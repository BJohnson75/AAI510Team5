{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5AnuNsdnB6e"
   },
   "source": [
    "# Team 5 Final Project - Manikandan Ramalingam, Jay Patel, Brian Johnson\n",
    "# Credit Default Analysis\n",
    "\n",
    "In machine learning, the algorithms are just the tools, the raw material is the data - it's the ore that makes the gold. Thus, to build useful models, one needs to get intimate with data â€” it's strengths, flaws, nuances, patterns, cycles, etc. Graphical data analysis is much more than mere visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feel the Credit Default Risk Data set\n",
    "\n",
    "  There are multiple ways to analyze the data like human judgement based on the experience in the domain, utilizing various statistical and graphical analysis tools or picking features based on popular existing well defined models like Random forest classification, Principal component analysis etc. But, for all, the preliminary step would be to get the feel of the data set. The shape would provide the number of rows and columns (or features). This would enable us to use appropriate techniques for data cleansing. The below code does check the shape and type of parameters by printing the top 5 rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJskzz-dGyp8"
   },
   "source": [
    "## Get the Credit Default Dataset\n",
    "By convention, seaborn is imported with the shorthand 'sns'. Seaborn includes a few example datasets. Let's import seaborn and load a dataset to start plotting. spellling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "ziwyDS0vMllO",
    "outputId": "91d46e01-6891-4b8c-f6e7-3246ac6b46ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe (row, col): (153755, 122) \r\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(153755, 122)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt #to allow subplot creation\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch the train data into the data frame\n",
    "df = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "# Apply the seaborn theme\n",
    "sns.set_theme() #overwrite default Matplotlib styling parameters\n",
    "\n",
    "shape = df.shape\n",
    "print(\"Shape of the dataframe (row, col):\",shape,\"\\r\\n\")\n",
    "\n",
    "# Show the dataframe\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze a Target variable without Feature Engineering\n",
    "\n",
    "First, use all 121 features to analyze the target variable. Use GBC Tree classifier to predict the values and test for accuracy. Since we are not using Feature Engineering, we can select only numeric columns. So, first select all numeric columns from the data frame. Otherwise, we cannot apply the model classification with the combination of strings and numeric values. Also, drop the entire row when null values are present. Although this a feature enginnering step, without this basic data cleansing, we cannot predict the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153755, 106)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Function to impute NaN with mean and floor the result\n",
    "def impute_and_floor(df):\n",
    "    # Select numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Impute NaN with mean and floor the values\n",
    "    for col in numeric_cols.columns:\n",
    "        mean_value = numeric_cols[col].mean()\n",
    "        df[col].fillna(mean_value, inplace=True)\n",
    "        df[col] = np.floor(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df_cleaned = impute_and_floor(numeric_df)\n",
    "\n",
    "df_cleaned.head()\n",
    "df_cleaned.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Precision, Recall, F1-score and Accuracy without Feature Engineering Using GradientBoostingClassifier\n",
    "\n",
    "This data will provide the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     28319\n",
      "         1.0       0.00      0.00      0.00      2432\n",
      "\n",
      "    accuracy                           0.92     30751\n",
      "   macro avg       0.46      0.50      0.48     30751\n",
      "weighted avg       0.85      0.92      0.88     30751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Just drop the target column from 106 numeric feature columns\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_cleaned.drop(['TARGET'], axis='columns'), df_cleaned.TARGET, test_size=0.2)\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_clf.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Human Judgement First\n",
    "\n",
    "   There are 122 columns (or features) in this credit risk default file. Since we are predicting whether to provide loan or not based on the credit profile, this is a classification task in Machine Learning Paradigm. The loan re-payment depends on various factors like income, number of children in family, family members, type of occupation, assets, previous credits, previous credit account defaults, desperate to get loan (credit enquiries in past few months), instances of 30/60 day past due or earlier credits etc. So, before applying any statistical, graphical or Machine learning models, some important features are selected based on experience (application for earlier credits would also be considered experience) in the given domain.\n",
    "\n",
    "The top features based on human judgement and reasons is below.\n",
    "\n",
    "1. AMT_INCOME_TOTAL - Income of Client\n",
    "2. AMT_CREDIT - Loan Amount\n",
    "3. AMT_ANNUITY - Loan Annuity\n",
    "4. AMT_GOODS_PRICE - For Consumer loans\n",
    "5. NAME_INCOME_TYPE - Income through family business, working salaried professional or Other)\n",
    "6. NAME_EDUCATION_TYPE - This is important because well educated individuals tend to get more salaries over time   \n",
    "                         and experience.\n",
    "7. NAME_HOUSING_TYPE -  Rent or Own plays a role.\n",
    "8. NAME_FAMILY_STATUS - Married, separated and paying alimony matters.\n",
    "9. CNT_CHILDREN - Number of children if a person has to do child support.\n",
    "10. FLAG_OWN_CAR - Do you own a car\n",
    "11. FLAG_OWN_REALTY - Own any Realty\n",
    "12. DAYS_BIRTH - How many since the client is born. The more in the range (>21 < 37), the better.\n",
    "13. DAYS_EMPLOYED - Employment days. The more years results in higher salary.\n",
    "14. FLAG_CONT_MOBILE - Mobile phone reachable to call in case of default\n",
    "15. CNT_FAM_MEMBERS - Number of family members\n",
    "16. REG_REGION_NOT_LIVE_REGION - If permanent address matches with contact address\n",
    "17. LIVE_REGION_NOT_WORK_REGION - If work address not closer to contact address\n",
    "18. ORGANIZATION_TYPE - Type of organization where client works. This is important to judge future growth on \n",
    "                        client's salary.\n",
    "19. DEF_60_CNT_SOCIAL_CIRCLE - How many observation of client's social surroundings defaulted on 60 DPD (days past due) \n",
    "20. AMT_REQ_CREDIT_BUREAU_MON - Number of enquiries to Credit Bureau about the client one month before application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 20 Features Extraction\n",
    "  \n",
    "  Extract the features in a data frame. Also, do some data cleansing with null values populated with a mean value of columns. This will make the analysis of the feature set easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>26446.5</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Married</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>-16180</td>\n",
       "      <td>-2037</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>733176.0</td>\n",
       "      <td>21438.0</td>\n",
       "      <td>612000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>-14969</td>\n",
       "      <td>-162</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189000.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>62541.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>-22213</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175500.0</td>\n",
       "      <td>494550.0</td>\n",
       "      <td>45490.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>-19301</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000.0</td>\n",
       "      <td>1724688.0</td>\n",
       "      <td>54283.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>-18409</td>\n",
       "      <td>-886</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0          157500.0    900000.0      26446.5         900000.0   \n",
       "1           90000.0    733176.0      21438.0         612000.0   \n",
       "2          189000.0   1795500.0      62541.0        1795500.0   \n",
       "3          175500.0    494550.0      45490.5         450000.0   \n",
       "4          270000.0   1724688.0      54283.5        1575000.0   \n",
       "\n",
       "  NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  NAME_HOUSING_TYPE  \\\n",
       "0          Working  Secondary / secondary special  House / apartment   \n",
       "1          Working               Higher education  House / apartment   \n",
       "2        Pensioner  Secondary / secondary special  House / apartment   \n",
       "3        Pensioner               Higher education  House / apartment   \n",
       "4          Working               Higher education  House / apartment   \n",
       "\n",
       "     NAME_FAMILY_STATUS  CNT_CHILDREN FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0               Married             1            N               Y   \n",
       "1  Single / not married             1            N               Y   \n",
       "2               Married             0            Y               Y   \n",
       "3               Married             0            Y               N   \n",
       "4               Married             0            Y               Y   \n",
       "\n",
       "   DAYS_BIRTH  DAYS_EMPLOYED  FLAG_CONT_MOBILE  CNT_FAM_MEMBERS  \\\n",
       "0      -16180          -2037                 1              3.0   \n",
       "1      -14969           -162                 1              2.0   \n",
       "2      -22213         365243                 1              2.0   \n",
       "3      -19301         365243                 1              2.0   \n",
       "4      -18409           -886                 1              2.0   \n",
       "\n",
       "   REG_REGION_NOT_LIVE_REGION  LIVE_REGION_NOT_WORK_REGION  \\\n",
       "0                           0                            0   \n",
       "1                           0                            0   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "\n",
       "        ORGANIZATION_TYPE  DEF_60_CNT_SOCIAL_CIRCLE  AMT_REQ_CREDIT_BUREAU_MON  \n",
       "0  Business Entity Type 3                       0.0                        0.0  \n",
       "1                    Bank                       0.0                        0.0  \n",
       "2                     XNA                       0.0                        0.0  \n",
       "3                     XNA                       0.0                        0.0  \n",
       "4           Self-employed                       0.0                        0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract these 21 variables\n",
    "df_extract_21 = df[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                   'NAME_EDUCATION_TYPE', 'NAME_HOUSING_TYPE', 'NAME_FAMILY_STATUS', 'CNT_CHILDREN', 'FLAG_OWN_CAR',\n",
    "                   'FLAG_OWN_REALTY', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'FLAG_CONT_MOBILE', 'CNT_FAM_MEMBERS', \n",
    "                   'REG_REGION_NOT_LIVE_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'ORGANIZATION_TYPE',\n",
    "                   'DEF_60_CNT_SOCIAL_CIRCLE', 'AMT_REQ_CREDIT_BUREAU_MON']]\n",
    "df_extract_21.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Engineering Technique1 - Mean Imputation and Normalization\n",
    "\n",
    "For all the numeric values in 20 features set, populate the mean. Also, select the minimum value when selecting the mean as some features might not be floating point values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-fe77968494d2>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[columns_to_fill] = df_extract_21[columns_to_fill].fillna(mean_values)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>26446.5</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Married</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>-16180</td>\n",
       "      <td>-2037</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>733176.0</td>\n",
       "      <td>21438.0</td>\n",
       "      <td>612000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>-14969</td>\n",
       "      <td>-162</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bank</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189000.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>62541.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>-22213</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175500.0</td>\n",
       "      <td>494550.0</td>\n",
       "      <td>45490.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>-19301</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000.0</td>\n",
       "      <td>1724688.0</td>\n",
       "      <td>54283.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>-18409</td>\n",
       "      <td>-886</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0          157500.0    900000.0      26446.5         900000.0   \n",
       "1           90000.0    733176.0      21438.0         612000.0   \n",
       "2          189000.0   1795500.0      62541.0        1795500.0   \n",
       "3          175500.0    494550.0      45490.5         450000.0   \n",
       "4          270000.0   1724688.0      54283.5        1575000.0   \n",
       "\n",
       "  NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  NAME_HOUSING_TYPE  \\\n",
       "0          Working  Secondary / secondary special  House / apartment   \n",
       "1          Working               Higher education  House / apartment   \n",
       "2        Pensioner  Secondary / secondary special  House / apartment   \n",
       "3        Pensioner               Higher education  House / apartment   \n",
       "4          Working               Higher education  House / apartment   \n",
       "\n",
       "     NAME_FAMILY_STATUS  CNT_CHILDREN FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0               Married             1            N               Y   \n",
       "1  Single / not married             1            N               Y   \n",
       "2               Married             0            Y               Y   \n",
       "3               Married             0            Y               N   \n",
       "4               Married             0            Y               Y   \n",
       "\n",
       "   DAYS_BIRTH  DAYS_EMPLOYED  FLAG_CONT_MOBILE  CNT_FAM_MEMBERS  \\\n",
       "0      -16180          -2037                 1              3.0   \n",
       "1      -14969           -162                 1              2.0   \n",
       "2      -22213         365243                 1              2.0   \n",
       "3      -19301         365243                 1              2.0   \n",
       "4      -18409           -886                 1              2.0   \n",
       "\n",
       "   REG_REGION_NOT_LIVE_REGION  LIVE_REGION_NOT_WORK_REGION  \\\n",
       "0                           0                            0   \n",
       "1                           0                            0   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "\n",
       "        ORGANIZATION_TYPE  DEF_60_CNT_SOCIAL_CIRCLE  AMT_REQ_CREDIT_BUREAU_MON  \n",
       "0  Business Entity Type 3                       0.0                        0.0  \n",
       "1                    Bank                       0.0                        0.0  \n",
       "2                     XNA                       0.0                        0.0  \n",
       "3                     XNA                       0.0                        0.0  \n",
       "4           Self-employed                       0.0                        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract these 21 variables\n",
    "df_extract_21 = df[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                   'NAME_EDUCATION_TYPE', 'NAME_HOUSING_TYPE', 'NAME_FAMILY_STATUS', 'CNT_CHILDREN', 'FLAG_OWN_CAR',\n",
    "                   'FLAG_OWN_REALTY', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'FLAG_CONT_MOBILE', 'CNT_FAM_MEMBERS', \n",
    "                   'REG_REGION_NOT_LIVE_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'ORGANIZATION_TYPE',\n",
    "                   'DEF_60_CNT_SOCIAL_CIRCLE', 'AMT_REQ_CREDIT_BUREAU_MON']]\n",
    "\n",
    "# Replace NaN values in specific columns with mean\n",
    "columns_to_fill = ['AMT_ANNUITY', 'AMT_GOODS_PRICE', 'CNT_FAM_MEMBERS', 'DEF_60_CNT_SOCIAL_CIRCLE', 'AMT_REQ_CREDIT_BUREAU_MON']\n",
    "\n",
    "# Calculate the mean of specific columns and round down to the nearest integer\n",
    "mean_values = df_extract_21[columns_to_fill].mean().apply(np.floor)\n",
    "\n",
    "# Fill NaN values in df_extract_21 with the calculated mean values\n",
    "df_extract_21[columns_to_fill] = df_extract_21[columns_to_fill].fillna(mean_values)\n",
    "df_extract_21.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Technique 2 - Encoding Categorical Variables\n",
    "\n",
    "Convert the categorical variables to numeric values using encoding tenchnique. Also, convert few columns selected with negative values to positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-bc6de7c0550c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[col] = label_encoder.fit_transform(df_extract_21[col])\n",
      "<ipython-input-103-bc6de7c0550c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[col] = label_encoder.fit_transform(df_extract_21[col])\n",
      "<ipython-input-103-bc6de7c0550c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[col] = label_encoder.fit_transform(df_extract_21[col])\n",
      "<ipython-input-103-bc6de7c0550c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[col] = label_encoder.fit_transform(df_extract_21[col])\n",
      "<ipython-input-103-bc6de7c0550c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[col] = label_encoder.fit_transform(df_extract_21[col])\n",
      "<ipython-input-103-bc6de7c0550c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[col] = label_encoder.fit_transform(df_extract_21[col])\n",
      "<ipython-input-103-bc6de7c0550c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[col] = label_encoder.fit_transform(df_extract_21[col])\n",
      "<ipython-input-103-bc6de7c0550c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[col] = label_encoder.fit_transform(df_extract_21[col])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>26446.5</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16180</td>\n",
       "      <td>2037</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>733176.0</td>\n",
       "      <td>21438.0</td>\n",
       "      <td>612000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14969</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189000.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>62541.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22213</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175500.0</td>\n",
       "      <td>494550.0</td>\n",
       "      <td>45490.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19301</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000.0</td>\n",
       "      <td>1724688.0</td>\n",
       "      <td>54283.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18409</td>\n",
       "      <td>886</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0          157500.0    900000.0      26446.5         900000.0   \n",
       "1           90000.0    733176.0      21438.0         612000.0   \n",
       "2          189000.0   1795500.0      62541.0        1795500.0   \n",
       "3          175500.0    494550.0      45490.5         450000.0   \n",
       "4          270000.0   1724688.0      54283.5        1575000.0   \n",
       "\n",
       "   NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  NAME_HOUSING_TYPE  \\\n",
       "0                 7                    4                  1   \n",
       "1                 7                    1                  1   \n",
       "2                 3                    4                  1   \n",
       "3                 3                    1                  1   \n",
       "4                 7                    1                  1   \n",
       "\n",
       "   NAME_FAMILY_STATUS  CNT_CHILDREN  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0                   1             1             0                1   \n",
       "1                   3             1             0                1   \n",
       "2                   1             0             1                1   \n",
       "3                   1             0             1                0   \n",
       "4                   1             0             1                1   \n",
       "\n",
       "   DAYS_BIRTH  DAYS_EMPLOYED  FLAG_CONT_MOBILE  CNT_FAM_MEMBERS  \\\n",
       "0       16180           2037                 1              3.0   \n",
       "1       14969            162                 1              2.0   \n",
       "2       22213         365243                 1              2.0   \n",
       "3       19301         365243                 1              2.0   \n",
       "4       18409            886                 1              2.0   \n",
       "\n",
       "   REG_REGION_NOT_LIVE_REGION  LIVE_REGION_NOT_WORK_REGION  ORGANIZATION_TYPE  \\\n",
       "0                           0                            0                  5   \n",
       "1                           0                            0                  2   \n",
       "2                           0                            0                 57   \n",
       "3                           0                            0                 57   \n",
       "4                           0                            0                 42   \n",
       "\n",
       "   DEF_60_CNT_SOCIAL_CIRCLE  AMT_REQ_CREDIT_BUREAU_MON  \n",
       "0                       0.0                        0.0  \n",
       "1                       0.0                        0.0  \n",
       "2                       0.0                        0.0  \n",
       "3                       0.0                        0.0  \n",
       "4                       0.0                        0.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "columns_to_encode = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_HOUSING_TYPE', 'NAME_FAMILY_STATUS', \n",
    "                     'ORGANIZATION_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'FLAG_CONT_MOBILE']\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "for col in columns_to_encode:\n",
    "    df_extract_21[col] = label_encoder.fit_transform(df_extract_21[col])\n",
    "df_extract_21.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Technique 3 - Data Transformation\n",
    "\n",
    "Note that Days birth and days employed are negative values. It is transformed to positive values for getting good prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8bdef085ec8d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_21[col] = df_extract_21[col].abs()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>26446.5</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16180</td>\n",
       "      <td>2037</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>733176.0</td>\n",
       "      <td>21438.0</td>\n",
       "      <td>612000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14969</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189000.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>62541.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22213</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175500.0</td>\n",
       "      <td>494550.0</td>\n",
       "      <td>45490.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19301</td>\n",
       "      <td>365243</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000.0</td>\n",
       "      <td>1724688.0</td>\n",
       "      <td>54283.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18409</td>\n",
       "      <td>886</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0          157500.0    900000.0      26446.5         900000.0   \n",
       "1           90000.0    733176.0      21438.0         612000.0   \n",
       "2          189000.0   1795500.0      62541.0        1795500.0   \n",
       "3          175500.0    494550.0      45490.5         450000.0   \n",
       "4          270000.0   1724688.0      54283.5        1575000.0   \n",
       "\n",
       "   NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  NAME_HOUSING_TYPE  \\\n",
       "0                 7                    4                  1   \n",
       "1                 7                    1                  1   \n",
       "2                 3                    4                  1   \n",
       "3                 3                    1                  1   \n",
       "4                 7                    1                  1   \n",
       "\n",
       "   NAME_FAMILY_STATUS  CNT_CHILDREN  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0                   1             1             0                1   \n",
       "1                   3             1             0                1   \n",
       "2                   1             0             1                1   \n",
       "3                   1             0             1                0   \n",
       "4                   1             0             1                1   \n",
       "\n",
       "   DAYS_BIRTH  DAYS_EMPLOYED  FLAG_CONT_MOBILE  CNT_FAM_MEMBERS  \\\n",
       "0       16180           2037                 1              3.0   \n",
       "1       14969            162                 1              2.0   \n",
       "2       22213         365243                 1              2.0   \n",
       "3       19301         365243                 1              2.0   \n",
       "4       18409            886                 1              2.0   \n",
       "\n",
       "   REG_REGION_NOT_LIVE_REGION  LIVE_REGION_NOT_WORK_REGION  ORGANIZATION_TYPE  \\\n",
       "0                           0                            0                  5   \n",
       "1                           0                            0                  2   \n",
       "2                           0                            0                 57   \n",
       "3                           0                            0                 57   \n",
       "4                           0                            0                 42   \n",
       "\n",
       "   DEF_60_CNT_SOCIAL_CIRCLE  AMT_REQ_CREDIT_BUREAU_MON  \n",
       "0                       0.0                        0.0  \n",
       "1                       0.0                        0.0  \n",
       "2                       0.0                        0.0  \n",
       "3                       0.0                        0.0  \n",
       "4                       0.0                        0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert negative to positive values\n",
    "columns_to_convert_positive = ['DAYS_BIRTH', 'DAYS_EMPLOYED']\n",
    "for col in columns_to_convert_positive:\n",
    "    df_extract_21[col] = df_extract_21[col].abs()\n",
    "    \n",
    "df_extract_21.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Engineering Technique 4 - Dimensionality Reduction to Extract 10 Most Important Features from 21 \n",
    "  \n",
    "  Extract the 10 most important features in a data frame out of 21. There are many techniques that can be used for this.\n",
    "  1. Use Random Forest classifier and select top 10.\n",
    "  2. Use Prinicipal Component Analysis.\n",
    "  3. SelectKBest an univariate method to select K=10 best features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest Classification with Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features from SelectKBest with chi2 classification:\n",
      "\n",
      "Index(['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
      "       'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'DAYS_BIRTH',\n",
      "       'DAYS_EMPLOYED', 'ORGANIZATION_TYPE', 'DEF_60_CNT_SOCIAL_CIRCLE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Generate a sample regression dataset\n",
    "#X, y = chi2(n_samples=df_extract_21.shape[0], n_features=df_extract_21.shape[1], random_state=42)\n",
    "# Perform feature selection using chi-squared test\n",
    "selector = SelectKBest(score_func=chi2, k=10)  # Select top 10 features\n",
    "y= df[['TARGET']]\n",
    "X_new = selector.fit_transform(df_extract_21, y)\n",
    "# Print the selected features\n",
    "selected_features = df_extract_21.columns[selector.get_support()]\n",
    "print(\"\\nSelected features from SelectKBest with chi2 classification:\\n\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier to identify top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Features from Random Forest classification:\n",
      "\n",
      "DAYS_BIRTH\n",
      "AMT_ANNUITY\n",
      "DAYS_EMPLOYED\n",
      "AMT_CREDIT\n",
      "AMT_INCOME_TOTAL\n",
      "AMT_GOODS_PRICE\n",
      "ORGANIZATION_TYPE\n",
      "NAME_FAMILY_STATUS\n",
      "CNT_FAM_MEMBERS\n",
      "CNT_CHILDREN\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "y= df[['TARGET']]\n",
    "rf_model.fit(df_extract_21, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Get indices of top 10 features\n",
    "top10_indices = np.argsort(importances)[::-1][:10]\n",
    "print(\"\\nSelected Features from Random Forest classification:\\n\")\n",
    "for i, idx in enumerate(top10_indices):\n",
    "    print(df_extract_21.columns[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Analysis (unsupervised) to identify top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features:\n",
      "['NAME_EDUCATION_TYPE', 'AMT_INCOME_TOTAL', 'CNT_CHILDREN', 'ORGANIZATION_TYPE', 'AMT_GOODS_PRICE', 'DAYS_EMPLOYED', 'NAME_INCOME_TYPE', 'DAYS_BIRTH', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'AMT_ANNUITY', 'CNT_FAM_MEMBERS', 'AMT_CREDIT']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize PCA with desired number of components (e.g., 10 for selecting top 10 components)\n",
    "n_components = 10\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit PCA on the data and transform it\n",
    "X_pca = pca.fit_transform(df_extract_21)\n",
    "\n",
    "# Optionally, you can also access the principal components (eigenvectors)\n",
    "principal_components = pca.components_\n",
    "\n",
    "# Get the indices of the top 10 principal components with the largest explained variance\n",
    "top10_indices = np.argsort(pca.explained_variance_ratio_)[::-1][:10]\n",
    "\n",
    "# Get the names of the top 10 features corresponding to the top principal components\n",
    "top10_features = []\n",
    "for idx in top10_indices:\n",
    "    component = principal_components[idx]\n",
    "    relevant_features = df_extract_21.columns[np.abs(component) > 0.1]\n",
    "    top10_features.extend(relevant_features)\n",
    "\n",
    "# Remove duplicates (if any)\n",
    "top10_features = list(set(top10_features))\n",
    "\n",
    "# Print the names of the top 10 features\n",
    "print(\"Top 10 features:\")\n",
    "print(top10_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on Top 10 features from above analysis\n",
    "\n",
    "Top 10 features based on mode from above 3 supervised/unsupervised analysis results:-\n",
    "\n",
    "'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE'\n",
    "'NAME_INCOME_TYPEâ€™, 'NAME_EDUCATION_TYPEâ€™, 'DAYS_BIRTHâ€™, 'DAYS_EMPLOYED'\n",
    "'ORGANIZATION_TYPEâ€™, 'CNT_FAM_MEMBERS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>26446.5</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>16180</td>\n",
       "      <td>2037</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>733176.0</td>\n",
       "      <td>21438.0</td>\n",
       "      <td>612000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14969</td>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189000.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>62541.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22213</td>\n",
       "      <td>365243</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175500.0</td>\n",
       "      <td>494550.0</td>\n",
       "      <td>45490.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19301</td>\n",
       "      <td>365243</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000.0</td>\n",
       "      <td>1724688.0</td>\n",
       "      <td>54283.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>18409</td>\n",
       "      <td>886</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0          157500.0    900000.0      26446.5         900000.0   \n",
       "1           90000.0    733176.0      21438.0         612000.0   \n",
       "2          189000.0   1795500.0      62541.0        1795500.0   \n",
       "3          175500.0    494550.0      45490.5         450000.0   \n",
       "4          270000.0   1724688.0      54283.5        1575000.0   \n",
       "\n",
       "   NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0                 7                    4       16180           2037   \n",
       "1                 7                    1       14969            162   \n",
       "2                 3                    4       22213         365243   \n",
       "3                 3                    1       19301         365243   \n",
       "4                 7                    1       18409            886   \n",
       "\n",
       "   ORGANIZATION_TYPE  CNT_FAM_MEMBERS  \n",
       "0                  5              3.0  \n",
       "1                  2              2.0  \n",
       "2                 57              2.0  \n",
       "3                 57              2.0  \n",
       "4                 42              2.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                   'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                   'CNT_FAM_MEMBERS']]\n",
    "df_extract_10.head()\n",
    "#df_extract_10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction After Applying Feature Engineering Technique\n",
    "\n",
    "Used RandomForestClassifier on the top 10 features after Feature Engineering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     28294\n",
      "           1       0.21      0.00      0.00      2457\n",
      "\n",
      "    accuracy                           0.92     30751\n",
      "   macro avg       0.57      0.50      0.48     30751\n",
      "weighted avg       0.86      0.92      0.88     30751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train Random Forest model\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_extract_10, df['TARGET'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "From the analysis above with human judgement, different models and graphical analysis it seems the top 10 features out of 122 features in the train_set.csv seems to be 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPEâ€™, 'NAME_EDUCATION_TYPEâ€™, 'DAYS_BIRTHâ€™, 'DAYS_EMPLOYED'\n",
    "'ORGANIZATION_TYPEâ€™, 'CNT_FAM_MEMBERS'. This will enable the credit decision when applied with different machine learning models and hyper parameter tuning. On classification report analysis, the report is similar to the one we have at the top with 106 features. But, it took long time to train those compared to reduced dimensions of 10 values. So, it shouldn't be interpreted that we can use entire 106 features. It boils down to just using top 10 features perform with accuracy of 92%. This shows the importance of Feature Engineering.\n",
    "\n",
    "Disclosure\n",
    "This is based on only 122 features and not the data in other csv files. There might be appropriate data in other files which might be more relevant. This exercise is focused on train_test.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>26446.5</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>16180</td>\n",
       "      <td>2037</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>733176.0</td>\n",
       "      <td>21438.0</td>\n",
       "      <td>612000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14969</td>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189000.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>62541.0</td>\n",
       "      <td>1795500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22213</td>\n",
       "      <td>365243</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175500.0</td>\n",
       "      <td>494550.0</td>\n",
       "      <td>45490.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19301</td>\n",
       "      <td>365243</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000.0</td>\n",
       "      <td>1724688.0</td>\n",
       "      <td>54283.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>18409</td>\n",
       "      <td>886</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0          157500.0    900000.0      26446.5         900000.0   \n",
       "1           90000.0    733176.0      21438.0         612000.0   \n",
       "2          189000.0   1795500.0      62541.0        1795500.0   \n",
       "3          175500.0    494550.0      45490.5         450000.0   \n",
       "4          270000.0   1724688.0      54283.5        1575000.0   \n",
       "\n",
       "   NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0                 7                    4       16180           2037   \n",
       "1                 7                    1       14969            162   \n",
       "2                 3                    4       22213         365243   \n",
       "3                 3                    1       19301         365243   \n",
       "4                 7                    1       18409            886   \n",
       "\n",
       "   ORGANIZATION_TYPE  CNT_FAM_MEMBERS  TARGET  \n",
       "0                  5              3.0       0  \n",
       "1                  2              2.0       0  \n",
       "2                 57              2.0       0  \n",
       "3                 57              2.0       0  \n",
       "4                 42              2.0       0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Cleansed data frame with 10 features after applying Feature Engineering is shown below. \n",
    "# Further model fits will be done using this\n",
    "df_extract_10 = df_extract_10.join(df[['TARGET']])\n",
    "df_extract_10.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-118-ad48fd5f8cc4>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
      "<ipython-input-118-ad48fd5f8cc4>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
      "<ipython-input-118-ad48fd5f8cc4>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-118-ad48fd5f8cc4>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-118-ad48fd5f8cc4>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Worthiness Score: 14\n",
      "Accuracy: 0.9201001593444116\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "AUC Score: 0.6066785697096011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     28294\n",
      "           1       0.00      0.00      0.00      2457\n",
      "\n",
      "    accuracy                           0.92     30751\n",
      "   macro avg       0.46      0.50      0.48     30751\n",
      "weighted avg       0.85      0.92      0.88     30751\n",
      "\n",
      "count    153755.000000\n",
      "mean          7.591512\n",
      "std           5.949095\n",
      "min           0.000000\n",
      "25%           4.000000\n",
      "50%           6.000000\n",
      "75%          11.000000\n",
      "max          45.000000\n",
      "Name: Credit Worthiness Score, dtype: float64\n",
      "Credit Worthiness Score\n",
      "0     13268\n",
      "1      6110\n",
      "2      4886\n",
      "3     13645\n",
      "4      8785\n",
      "5     25467\n",
      "6      9921\n",
      "7     14135\n",
      "8      5615\n",
      "9      5103\n",
      "10     6159\n",
      "11     6221\n",
      "12     6737\n",
      "13     3137\n",
      "14     3737\n",
      "15     3657\n",
      "16     3188\n",
      "17     3835\n",
      "18     2655\n",
      "19     2530\n",
      "20      850\n",
      "21      149\n",
      "22      202\n",
      "23      390\n",
      "24     1414\n",
      "25      467\n",
      "27       81\n",
      "28      196\n",
      "30      585\n",
      "33       79\n",
      "34      115\n",
      "35      137\n",
      "36      115\n",
      "40       74\n",
      "45      110\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-118-ad48fd5f8cc4>:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10['Credit Worthiness Score'] = scores\n"
     ]
    }
   ],
   "source": [
    "#DecisionTree w/ no creditscore range limit w/ metric scores\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Example data loading (adjust the path and file name as needed)\n",
    "df_extract_21 = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "\n",
    "# Extract relevant features\n",
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                               'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                               'CNT_FAM_MEMBERS']]\n",
    "\n",
    "# Ensure the target column is present\n",
    "if 'TARGET' not in df_extract_21.columns:\n",
    "    raise KeyError(\"The target column 'TARGET' is not found in the dataset.\")\n",
    "\n",
    "# Handle missing values\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "categorical_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "\n",
    "df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
    "for column in categorical_columns:\n",
    "    df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = df_extract_10\n",
    "target = df_extract_21['TARGET']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Decision Tree model with adjusted parameters\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42, min_samples_leaf=50, max_depth=10)\n",
    "decision_tree_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Function to calculate credit worthiness score with a finer granularity\n",
    "def get_credit_worthiness_score(prob):\n",
    "    return int(prob * 100)  # Scaling probability to a score between 0 and 100\n",
    "\n",
    "# Make predictions on new data and get the probabilities\n",
    "new_data = pd.DataFrame({\n",
    "    'AMT_INCOME_TOTAL': [200000],\n",
    "    'AMT_CREDIT': [500000],\n",
    "    'AMT_ANNUITY': [25000],\n",
    "    'AMT_GOODS_PRICE': [450000],\n",
    "    'NAME_INCOME_TYPE': ['Working'],\n",
    "    'NAME_EDUCATION_TYPE': ['Higher education'],\n",
    "    'DAYS_BIRTH': [-10000],\n",
    "    'DAYS_EMPLOYED': [-2000],\n",
    "    'ORGANIZATION_TYPE': ['Business Entity Type 3'],\n",
    "    'CNT_FAM_MEMBERS': [2]\n",
    "})\n",
    "\n",
    "# Ensure new data columns match the training data\n",
    "new_data = new_data[features.columns]\n",
    "\n",
    "# Encode new data using the same label encoders\n",
    "for column in categorical_columns:\n",
    "    new_data[column] = label_encoders[column].transform(new_data[column])\n",
    "\n",
    "# Get the probability of the positive class\n",
    "prob = decision_tree_classifier.predict_proba(new_data)[:, 1][0]\n",
    "\n",
    "# Generate the credit worthiness score\n",
    "score = get_credit_worthiness_score(prob)\n",
    "print(f'Credit Worthiness Score: {score}')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree_classifier.predict(x_test)\n",
    "y_pred_proba = decision_tree_classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'AUC Score: {auc}')\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Predict probabilities for the entire dataset\n",
    "probabilities = decision_tree_classifier.predict_proba(features)[:, 1]\n",
    "\n",
    "# Generate credit worthiness scores\n",
    "scores = [get_credit_worthiness_score(prob) for prob in probabilities]\n",
    "\n",
    "# Add the scores to the DataFrame\n",
    "df_extract_10['Credit Worthiness Score'] = scores\n",
    "\n",
    "# Summarize the scores\n",
    "summary = df_extract_10['Credit Worthiness Score'].describe()\n",
    "print(summary)\n",
    "\n",
    "# Optionally, print the distribution of scores\n",
    "score_distribution = df_extract_10['Credit Worthiness Score'].value_counts().sort_index()\n",
    "print(score_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-120-3e5245198902>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
      "<ipython-input-120-3e5245198902>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
      "<ipython-input-120-3e5245198902>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-120-3e5245198902>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-120-3e5245198902>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Worthiness Score: 2\n",
      "Accuracy: 0.9201001593444116\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "AUC Score: 0.6066785697096011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     28294\n",
      "           1       0.00      0.00      0.00      2457\n",
      "\n",
      "    accuracy                           0.92     30751\n",
      "   macro avg       0.46      0.50      0.48     30751\n",
      "weighted avg       0.85      0.92      0.88     30751\n",
      "\n",
      "count    153755.000000\n",
      "mean          1.193964\n",
      "std           1.164563\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           1.000000\n",
      "75%           2.000000\n",
      "max           9.000000\n",
      "Name: Credit Worthiness Score, dtype: float64\n",
      "Credit Worthiness Score\n",
      "0    46694\n",
      "1    60241\n",
      "2    25991\n",
      "3    15865\n",
      "4     3005\n",
      "5      744\n",
      "6      779\n",
      "7      252\n",
      "8       74\n",
      "9      110\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-120-3e5245198902>:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10['Credit Worthiness Score'] = scores\n"
     ]
    }
   ],
   "source": [
    "#updated code to try and make score in range of 0-20\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Example data loading (adjust the path and file name as needed)\n",
    "df_extract_21 = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "\n",
    "# Extract relevant features\n",
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                               'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                               'CNT_FAM_MEMBERS']]\n",
    "\n",
    "# Ensure the target column is present\n",
    "if 'TARGET' not in df_extract_21.columns:\n",
    "    raise KeyError(\"The target column 'TARGET' is not found in the dataset.\")\n",
    "\n",
    "# Handle missing values\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "categorical_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "\n",
    "df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
    "for column in categorical_columns:\n",
    "    df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = df_extract_10\n",
    "target = df_extract_21['TARGET']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Decision Tree model with adjusted parameters\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42, min_samples_leaf=50, max_depth=10)\n",
    "decision_tree_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Function to calculate credit worthiness score with a range of 0 to 20\n",
    "def get_credit_worthiness_score(prob):\n",
    "    return int(prob * 20)  # Scaling probability to a score between 0 and 20\n",
    "\n",
    "# Make predictions on new data and get the probabilities\n",
    "new_data = pd.DataFrame({\n",
    "    'AMT_INCOME_TOTAL': [200000],\n",
    "    'AMT_CREDIT': [500000],\n",
    "    'AMT_ANNUITY': [25000],\n",
    "    'AMT_GOODS_PRICE': [450000],\n",
    "    'NAME_INCOME_TYPE': ['Working'],\n",
    "    'NAME_EDUCATION_TYPE': ['Higher education'],\n",
    "    'DAYS_BIRTH': [-10000],\n",
    "    'DAYS_EMPLOYED': [-2000],\n",
    "    'ORGANIZATION_TYPE': ['Business Entity Type 3'],\n",
    "    'CNT_FAM_MEMBERS': [2]\n",
    "})\n",
    "\n",
    "# Ensure new data columns match the training data\n",
    "new_data = new_data[features.columns]\n",
    "\n",
    "# Encode new data using the same label encoders\n",
    "for column in categorical_columns:\n",
    "    new_data[column] = label_encoders[column].transform(new_data[column])\n",
    "\n",
    "# Get the probability of the positive class\n",
    "prob = decision_tree_classifier.predict_proba(new_data)[:, 1][0]\n",
    "\n",
    "# Generate the credit worthiness score\n",
    "score = get_credit_worthiness_score(prob)\n",
    "print(f'Credit Worthiness Score: {score}')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree_classifier.predict(x_test)\n",
    "y_pred_proba = decision_tree_classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'AUC Score: {auc}')\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Predict probabilities for the entire dataset\n",
    "probabilities = decision_tree_classifier.predict_proba(features)[:, 1]\n",
    "\n",
    "# Generate credit worthiness scores\n",
    "scores = [get_credit_worthiness_score(prob) for prob in probabilities]\n",
    "\n",
    "# Add the scores to the DataFrame\n",
    "df_extract_10['Credit Worthiness Score'] = scores\n",
    "\n",
    "# Summarize the scores\n",
    "summary = df_extract_10['Credit Worthiness Score'].describe()\n",
    "print(summary)\n",
    "\n",
    "# Optionally, print the distribution of scores\n",
    "score_distribution = df_extract_10['Credit Worthiness Score'].value_counts().sort_index()\n",
    "print(score_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-121-3c7401192e7d>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
      "<ipython-input-121-3c7401192e7d>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
      "<ipython-input-121-3c7401192e7d>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-121-3c7401192e7d>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-121-3c7401192e7d>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-121-3c7401192e7d>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[numerical_columns] = scaler.fit_transform(features[numerical_columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Worthiness Score: 1\n",
      "count    153755.000000\n",
      "mean          1.138304\n",
      "std           0.703117\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           2.000000\n",
      "max          16.000000\n",
      "Name: Credit Worthiness Score, dtype: float64\n",
      "Credit Worthiness Score\n",
      "0     26867\n",
      "1     80638\n",
      "2     44384\n",
      "3      1863\n",
      "4         1\n",
      "5         1\n",
      "16        1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-121-3c7401192e7d>:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10['Credit Worthiness Score'] = scores\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression Model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Example data loading (adjust the path and file name as needed)\n",
    "df_extract_21 = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "\n",
    "# Extract relevant features\n",
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                               'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                               'CNT_FAM_MEMBERS']]\n",
    "\n",
    "# Ensure the target column is present\n",
    "if 'TARGET' not in df_extract_21.columns:\n",
    "    raise KeyError(\"The target column 'TARGET' is not found in the dataset.\")\n",
    "\n",
    "# Handle missing values\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "categorical_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "\n",
    "df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
    "for column in categorical_columns:\n",
    "    df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = df_extract_10\n",
    "target = df_extract_21['TARGET']\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "features[numerical_columns] = scaler.fit_transform(features[numerical_columns])\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Linear Regression model\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(x_train, y_train)\n",
    "\n",
    "# Function to calculate credit worthiness score with a range of 0 to 20\n",
    "def get_credit_worthiness_score(value):\n",
    "    return int(min(max(value * 20, 0), 20))  # Scale to 0-20 and clip values to be within the range\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = pd.DataFrame({\n",
    "    'AMT_INCOME_TOTAL': [200000],\n",
    "    'AMT_CREDIT': [500000],\n",
    "    'AMT_ANNUITY': [25000],\n",
    "    'AMT_GOODS_PRICE': [450000],\n",
    "    'NAME_INCOME_TYPE': ['Working'],\n",
    "    'NAME_EDUCATION_TYPE': ['Higher education'],\n",
    "    'DAYS_BIRTH': [-10000],\n",
    "    'DAYS_EMPLOYED': [-2000],\n",
    "    'ORGANIZATION_TYPE': ['Business Entity Type 3'],\n",
    "    'CNT_FAM_MEMBERS': [2]\n",
    "})\n",
    "\n",
    "# Ensure new data columns match the training data\n",
    "new_data = new_data[features.columns]\n",
    "\n",
    "# Encode and scale new data using the same label encoders and scaler\n",
    "for column in categorical_columns:\n",
    "    new_data[column] = label_encoders[column].transform(new_data[column])\n",
    "new_data[numerical_columns] = scaler.transform(new_data[numerical_columns])\n",
    "\n",
    "# Get the predicted value for the new data\n",
    "predicted_value = linear_regression_model.predict(new_data)[0]\n",
    "\n",
    "# Generate the credit worthiness score\n",
    "score = get_credit_worthiness_score(predicted_value)\n",
    "print(f'Credit Worthiness Score: {score}')\n",
    "\n",
    "# Predict values for the entire dataset\n",
    "predicted_values = linear_regression_model.predict(features)\n",
    "\n",
    "# Generate credit worthiness scores\n",
    "scores = [get_credit_worthiness_score(value) for value in predicted_values]\n",
    "\n",
    "# Add the scores to the DataFrame\n",
    "df_extract_10['Credit Worthiness Score'] = scores\n",
    "\n",
    "# Summarize the scores\n",
    "summary = df_extract_10['Credit Worthiness Score'].describe()\n",
    "print(summary)\n",
    "\n",
    "# Optionally, print the distribution of scores\n",
    "score_distribution = df_extract_10['Credit Worthiness Score'].value_counts().sort_index()\n",
    "print(score_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-122-9ca30e7f81b8>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
      "<ipython-input-122-9ca30e7f81b8>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
      "<ipython-input-122-9ca30e7f81b8>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-122-9ca30e7f81b8>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-122-9ca30e7f81b8>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-122-9ca30e7f81b8>:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[numerical_columns] = scaler.fit_transform(features[numerical_columns])\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.0\n",
      "ROC AUC Score: 0.6231901794918688\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.9201001593444116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     28294\n",
      "           1       0.00      0.00      0.00      2457\n",
      "\n",
      "    accuracy                           0.92     30751\n",
      "   macro avg       0.46      0.50      0.48     30751\n",
      "weighted avg       0.85      0.92      0.88     30751\n",
      "\n",
      "Credit Worthiness Score: 4\n",
      "count    153755.000000\n",
      "mean          3.975617\n",
      "std           0.754009\n",
      "min           0.000000\n",
      "25%           4.000000\n",
      "50%           4.000000\n",
      "75%           4.000000\n",
      "max          20.000000\n",
      "Name: Credit Worthiness Score, dtype: float64\n",
      "Credit Worthiness Score\n",
      "0         9\n",
      "1       106\n",
      "2      3207\n",
      "3     34244\n",
      "4     79854\n",
      "5     35423\n",
      "6       910\n",
      "8         1\n",
      "20        1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-122-9ca30e7f81b8>:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10['Credit Worthiness Score'] = scores\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "\n",
    "# Example data loading (adjust the path and file name as needed)\n",
    "df_extract_21 = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "\n",
    "# Extract relevant features\n",
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                               'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                               'CNT_FAM_MEMBERS']]\n",
    "\n",
    "# Ensure the target column is present\n",
    "if 'TARGET' not in df_extract_21.columns:\n",
    "    raise KeyError(\"The target column 'TARGET' is not found in the dataset.\")\n",
    "\n",
    "# Handle missing values\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "categorical_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "\n",
    "df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
    "for column in categorical_columns:\n",
    "    df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = df_extract_10\n",
    "target = df_extract_21['TARGET']\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "features[numerical_columns] = scaler.fit_transform(features[numerical_columns])\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Linear Regression model\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(x_train, y_train)\n",
    "\n",
    "# Function to calculate credit worthiness score with a range of 0 to 20\n",
    "def get_credit_worthiness_score(value, min_value, max_value):\n",
    "    # Scale the value to a range of 0 to 20\n",
    "    scaled_value = 20 * (value - min_value) / (max_value - min_value)\n",
    "    return int(min(max(scaled_value, 0), 20))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = linear_regression_model.predict(x_test)\n",
    "\n",
    "# Convert regression output to binary classification using a threshold (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "y_test_pred_class = (y_test_pred >= threshold).astype(int)\n",
    "\n",
    "# Calculate additional metrics\n",
    "f1 = f1_score(y_test, y_test_pred_class)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred_class)\n",
    "recall = recall_score(y_test, y_test_pred_class)\n",
    "accuracy = accuracy_score(y_test, y_test_pred_class)\n",
    "\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_test_pred_class))\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = pd.DataFrame({\n",
    "    'AMT_INCOME_TOTAL': [200000],\n",
    "    'AMT_CREDIT': [500000],\n",
    "    'AMT_ANNUITY': [25000],\n",
    "    'AMT_GOODS_PRICE': [450000],\n",
    "    'NAME_INCOME_TYPE': ['Working'],\n",
    "    'NAME_EDUCATION_TYPE': ['Higher education'],\n",
    "    'DAYS_BIRTH': [-10000],\n",
    "    'DAYS_EMPLOYED': [-2000],\n",
    "    'ORGANIZATION_TYPE': ['Business Entity Type 3'],\n",
    "    'CNT_FAM_MEMBERS': [2]\n",
    "})\n",
    "\n",
    "# Ensure new data columns match the training data\n",
    "new_data = new_data[features.columns]\n",
    "\n",
    "# Encode and scale new data using the same label encoders and scaler\n",
    "for column in categorical_columns:\n",
    "    new_data[column] = label_encoders[column].transform(new_data[column])\n",
    "new_data[numerical_columns] = scaler.transform(new_data[numerical_columns])\n",
    "\n",
    "# Get the predicted value for the new data\n",
    "predicted_value = linear_regression_model.predict(new_data)[0]\n",
    "\n",
    "# Get the minimum and maximum predicted values from the training set to use for scaling\n",
    "train_predictions = linear_regression_model.predict(x_train)\n",
    "min_train_pred = train_predictions.min()\n",
    "max_train_pred = train_predictions.max()\n",
    "\n",
    "# Generate the credit worthiness score\n",
    "score = get_credit_worthiness_score(predicted_value, min_train_pred, max_train_pred)\n",
    "print(f'Credit Worthiness Score: {score}')\n",
    "\n",
    "# Predict values for the entire dataset\n",
    "predicted_values = linear_regression_model.predict(features)\n",
    "\n",
    "# Generate credit worthiness scores\n",
    "scores = [get_credit_worthiness_score(value, min_train_pred, max_train_pred) for value in predicted_values]\n",
    "\n",
    "# Add the scores to the DataFrame\n",
    "df_extract_10['Credit Worthiness Score'] = scores\n",
    "\n",
    "# Summarize the scores\n",
    "summary = df_extract_10['Credit Worthiness Score'].describe()\n",
    "print(summary)\n",
    "\n",
    "# Optionally, print the distribution of scores\n",
    "score_distribution = df_extract_10['Credit Worthiness Score'].value_counts().sort_index()\n",
    "print(score_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-123-f82a35283643>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
      "<ipython-input-123-f82a35283643>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
      "<ipython-input-123-f82a35283643>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-123-f82a35283643>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-123-f82a35283643>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-123-f82a35283643>:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[numerical_columns] = scaler.fit_transform(features[numerical_columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.0\n",
      "ROC AUC Score: 0.6243525631028283\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.9201001593444116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     28294\n",
      "           1       0.00      0.00      0.00      2457\n",
      "\n",
      "    accuracy                           0.92     30751\n",
      "   macro avg       0.46      0.50      0.48     30751\n",
      "weighted avg       0.85      0.92      0.88     30751\n",
      "\n",
      "Credit Worthiness Score: 1\n",
      "count    153755.000000\n",
      "mean          1.128776\n",
      "std           0.758295\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           2.000000\n",
      "max          17.000000\n",
      "Name: Credit Worthiness Score, dtype: float64\n",
      "Credit Worthiness Score\n",
      "0     28171\n",
      "1     84527\n",
      "2     34518\n",
      "3      6191\n",
      "4       338\n",
      "5         8\n",
      "10        1\n",
      "17        1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/manikanr/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-123-f82a35283643>:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10['Credit Worthiness Score'] = scores\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "\n",
    "# Example data loading (adjust the path and file name as needed)\n",
    "df_extract_21 = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "\n",
    "# Extract relevant features\n",
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                               'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                               'CNT_FAM_MEMBERS']]\n",
    "\n",
    "# Ensure the target column is present\n",
    "if 'TARGET' not in df_extract_21.columns:\n",
    "    raise KeyError(\"The target column 'TARGET' is not found in the dataset.\")\n",
    "\n",
    "# Handle missing values\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "categorical_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "\n",
    "df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
    "for column in categorical_columns:\n",
    "    df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = df_extract_10\n",
    "target = df_extract_21['TARGET']\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "features[numerical_columns] = scaler.fit_transform(features[numerical_columns])\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=42)\n",
    "logistic_regression_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred_prob = logistic_regression_model.predict_proba(x_test)[:, 1]\n",
    "y_test_pred = logistic_regression_model.predict(x_test)\n",
    "\n",
    "# Calculate additional metrics\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Function to calculate credit worthiness score with a range of 0 to 20\n",
    "def get_credit_worthiness_score(prob):\n",
    "    return int(prob * 20)  # Scaling probability to a score between 0 and 20\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = pd.DataFrame({\n",
    "    'AMT_INCOME_TOTAL': [200000],\n",
    "    'AMT_CREDIT': [500000],\n",
    "    'AMT_ANNUITY': [25000],\n",
    "    'AMT_GOODS_PRICE': [450000],\n",
    "    'NAME_INCOME_TYPE': ['Working'],\n",
    "    'NAME_EDUCATION_TYPE': ['Higher education'],\n",
    "    'DAYS_BIRTH': [-10000],\n",
    "    'DAYS_EMPLOYED': [-2000],\n",
    "    'ORGANIZATION_TYPE': ['Business Entity Type 3'],\n",
    "    'CNT_FAM_MEMBERS': [2]\n",
    "})\n",
    "\n",
    "# Ensure new data columns match the training data\n",
    "new_data = new_data[features.columns]\n",
    "\n",
    "# Encode and scale new data using the same label encoders and scaler\n",
    "for column in categorical_columns:\n",
    "    new_data[column] = label_encoders[column].transform(new_data[column])\n",
    "new_data[numerical_columns] = scaler.transform(new_data[numerical_columns])\n",
    "\n",
    "# Get the probability of the positive class for the new data\n",
    "prob = logistic_regression_model.predict_proba(new_data)[:, 1][0]\n",
    "\n",
    "# Generate the credit worthiness score\n",
    "score = get_credit_worthiness_score(prob)\n",
    "print(f'Credit Worthiness Score: {score}')\n",
    "\n",
    "# Predict probabilities for the entire dataset\n",
    "probabilities = logistic_regression_model.predict_proba(features)[:, 1]\n",
    "\n",
    "# Generate credit worthiness scores\n",
    "scores = [get_credit_worthiness_score(prob) for prob in probabilities]\n",
    "\n",
    "# Add the scores to the DataFrame\n",
    "df_extract_10['Credit Worthiness Score'] = scores\n",
    "\n",
    "# Summarize the scores\n",
    "summary = df_extract_10['Credit Worthiness Score'].describe()\n",
    "print(summary)\n",
    "\n",
    "# Optionally, print the distribution of scores\n",
    "score_distribution = df_extract_10['Credit Worthiness Score'].value_counts().sort_index()\n",
    "print(score_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-124-4b249e2c7746>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
      "<ipython-input-124-4b249e2c7746>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
      "<ipython-input-124-4b249e2c7746>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-124-4b249e2c7746>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-124-4b249e2c7746>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-124-4b249e2c7746>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[numerical_columns] = scaler.fit_transform(features[numerical_columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.15301038284740748\n",
      "ROC AUC Score: 0.6240602374411662\n",
      "Precision: 0.08306575457210666\n",
      "Recall: 0.9686609686609686\n",
      "Accuracy: 0.14314981626613768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.07      0.13     28294\n",
      "           1       0.08      0.97      0.15      2457\n",
      "\n",
      "    accuracy                           0.14     30751\n",
      "   macro avg       0.52      0.52      0.14     30751\n",
      "weighted avg       0.89      0.14      0.13     30751\n",
      "\n",
      "Credit Worthiness Score: 10\n",
      "count    153755.000000\n",
      "mean          9.057488\n",
      "std           2.272846\n",
      "min           0.000000\n",
      "25%           8.000000\n",
      "50%           9.000000\n",
      "75%          11.000000\n",
      "max          18.000000\n",
      "Name: Credit Worthiness Score, dtype: float64\n",
      "Credit Worthiness Score\n",
      "0         5\n",
      "1        18\n",
      "2       163\n",
      "3       764\n",
      "4      2744\n",
      "5      6423\n",
      "6      9762\n",
      "7     18495\n",
      "8     24851\n",
      "9     23796\n",
      "10    23130\n",
      "11    20049\n",
      "12    14236\n",
      "13     7420\n",
      "14     1729\n",
      "15      163\n",
      "16        5\n",
      "18        2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-124-4b249e2c7746>:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10['Credit Worthiness Score'] = scores\n"
     ]
    }
   ],
   "source": [
    "#Updated Code with Class Weights and Adjusted Threshold\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "\n",
    "df_extract_21 = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "\n",
    "# Extract relevant features\n",
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                               'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                               'CNT_FAM_MEMBERS']]\n",
    "\n",
    "# Ensure the target column is present\n",
    "if 'TARGET' not in df_extract_21.columns:\n",
    "    raise KeyError(\"The target column 'TARGET' is not found in the dataset.\")\n",
    "\n",
    "# Handle missing values\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "categorical_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "\n",
    "df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
    "for column in categorical_columns:\n",
    "    df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = df_extract_10\n",
    "target = df_extract_21['TARGET']\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "features[numerical_columns] = scaler.fit_transform(features[numerical_columns])\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model with class weights\n",
    "logistic_regression_model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logistic_regression_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set with adjusted threshold\n",
    "y_test_pred_prob = logistic_regression_model.predict_proba(x_test)[:, 1]\n",
    "threshold = 0.3  # Adjusted threshold\n",
    "y_test_pred = (y_test_pred_prob >= threshold).astype(int)\n",
    "\n",
    "# Calculate additional metrics\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Function to calculate credit worthiness score with a range of 0 to 20\n",
    "def get_credit_worthiness_score(prob):\n",
    "    return int(prob * 20)  # Scaling probability to a score between 0 and 20\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = pd.DataFrame({\n",
    "    'AMT_INCOME_TOTAL': [200000],\n",
    "    'AMT_CREDIT': [500000],\n",
    "    'AMT_ANNUITY': [25000],\n",
    "    'AMT_GOODS_PRICE': [450000],\n",
    "    'NAME_INCOME_TYPE': ['Working'],\n",
    "    'NAME_EDUCATION_TYPE': ['Higher education'],\n",
    "    'DAYS_BIRTH': [-10000],\n",
    "    'DAYS_EMPLOYED': [-2000],\n",
    "    'ORGANIZATION_TYPE': ['Business Entity Type 3'],\n",
    "    'CNT_FAM_MEMBERS': [2]\n",
    "})\n",
    "\n",
    "# Ensure new data columns match the training data\n",
    "new_data = new_data[features.columns]\n",
    "\n",
    "# Encode and scale new data using the same label encoders and scaler\n",
    "for column in categorical_columns:\n",
    "    new_data[column] = label_encoders[column].transform(new_data[column])\n",
    "new_data[numerical_columns] = scaler.transform(new_data[numerical_columns])\n",
    "\n",
    "# Get the probability of the positive class for the new data\n",
    "prob = logistic_regression_model.predict_proba(new_data)[:, 1][0]\n",
    "\n",
    "# Generate the credit worthiness score\n",
    "score = get_credit_worthiness_score(prob)\n",
    "print(f'Credit Worthiness Score: {score}')\n",
    "\n",
    "# Predict probabilities for the entire dataset\n",
    "probabilities = logistic_regression_model.predict_proba(features)[:, 1]\n",
    "\n",
    "# Generate credit worthiness scores\n",
    "scores = [get_credit_worthiness_score(prob) for prob in probabilities]\n",
    "\n",
    "# Add the scores to the DataFrame\n",
    "df_extract_10['Credit Worthiness Score'] = scores\n",
    "\n",
    "# Summarize the scores\n",
    "summary = df_extract_10['Credit Worthiness Score'].describe()\n",
    "print(summary)\n",
    "\n",
    "# Optionally, print the distribution of scores\n",
    "score_distribution = df_extract_10['Credit Worthiness Score'].value_counts().sort_index()\n",
    "print(score_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-126-64fb78cd4935>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
      "<ipython-input-126-64fb78cd4935>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
      "<ipython-input-126-64fb78cd4935>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-126-64fb78cd4935>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-126-64fb78cd4935>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n"
     ]
    }
   ],
   "source": [
    "df_extract_21 = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "\n",
    "# Extract relevant features\n",
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                               'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                               'CNT_FAM_MEMBERS']]\n",
    "\n",
    "# Ensure the target column is present\n",
    "if 'TARGET' not in df_extract_21.columns:\n",
    "    raise KeyError(\"The target column 'TARGET' is not found in the dataset.\")\n",
    "\n",
    "# Handle missing values\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "categorical_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "\n",
    "df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
    "for column in categorical_columns:\n",
    "    df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = df_extract_10\n",
    "target = df_extract_21['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     28294\n",
      "           1       0.15      0.00      0.00      2457\n",
      "\n",
      "    accuracy                           0.92     30751\n",
      "   macro avg       0.54      0.50      0.48     30751\n",
      "weighted avg       0.86      0.92      0.88     30751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran the Random Forest again and checked for like results, with this in mind I moved forward with spreading the data out to see where the distribution of applicants fell out on a score from one to ten. The first iteration noted that 73 percent of them were at a score of four or lower, indicating to me that the output scoring data was unbalanced. Considering this, I increased the scoring system to 20 to get more granularity. This resulted in a cut line very low, probably in the 3 to 5 range. Those results are below. This will be compared to the XGBoost results to see how much of an idea we can get as to where our comfortability with lending decision will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Worthiness Score: 7\n"
     ]
    }
   ],
   "source": [
    "def get_credit_worthiness_score(prob):\n",
    "    return int(prob * 16 + 4)\n",
    "\n",
    "# Make predictions on new data and get the probabilities\n",
    "new_data = pd.DataFrame({\n",
    "    'AMT_INCOME_TOTAL': [200000],\n",
    "    'AMT_CREDIT': [500000],\n",
    "    'AMT_ANNUITY': [25000],\n",
    "    'AMT_GOODS_PRICE': [450000],\n",
    "    'NAME_INCOME_TYPE': ['Working'],\n",
    "    'NAME_EDUCATION_TYPE': ['Higher education'],\n",
    "    'DAYS_BIRTH': [-10000],\n",
    "    'DAYS_EMPLOYED': [-2000],\n",
    "    'ORGANIZATION_TYPE': ['Business Entity Type 3'],\n",
    "    'CNT_FAM_MEMBERS': [2]\n",
    "})\n",
    "\n",
    "# Encode new data using the same label encoders\n",
    "for column in categorical_columns:\n",
    "    new_data[column] = label_encoders[column].transform(new_data[column])\n",
    "\n",
    "# Get the probability of the positive class\n",
    "prob = rf_classifier.predict_proba(new_data)[:, 1][0]\n",
    "\n",
    "# Generate the credit worthiness score\n",
    "score = get_credit_worthiness_score(prob)\n",
    "print(f'Credit Worthiness Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    153755.000000\n",
      "mean          4.964736\n",
      "std           2.578755\n",
      "min           4.000000\n",
      "25%           4.000000\n",
      "50%           4.000000\n",
      "75%           5.000000\n",
      "max          18.000000\n",
      "Name: Credit Worthiness Score, dtype: float64\n",
      "Credit Worthiness Score\n",
      "4     112601\n",
      "5      22300\n",
      "6       5625\n",
      "7       2011\n",
      "8        857\n",
      "9        265\n",
      "10        86\n",
      "11        47\n",
      "12       215\n",
      "13      1502\n",
      "14      3903\n",
      "15      3304\n",
      "16       970\n",
      "17        66\n",
      "18         3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-41a2719daed5>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10['Credit Worthiness Score'] = scores\n"
     ]
    }
   ],
   "source": [
    "probabilities = rf_classifier.predict_proba(features)[:, 1]\n",
    "\n",
    "# Generate credit worthiness scores\n",
    "scores = [get_credit_worthiness_score(prob) for prob in probabilities]\n",
    "\n",
    "# Add the scores to the DataFrame\n",
    "df_extract_10['Credit Worthiness Score'] = scores\n",
    "\n",
    "# Summarize the scores\n",
    "summary = df_extract_10['Credit Worthiness Score'].describe()\n",
    "print(summary)\n",
    "\n",
    "# Optionally, print the distribution of scores\n",
    "score_distribution = df_extract_10['Credit Worthiness Score'].value_counts().sort_index()\n",
    "print(score_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data and features were the same. This resulted in a tighter spread of scores between 4 and 16, but were much more evenly distributed, indicating output scoring data was more balanced. I believe with the XGBoost data brought to a deciding body, we could more easily identify a cut score, likely between 5 and 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-133-9482c24a22a4>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
      "<ipython-input-133-9482c24a22a4>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
      "<ipython-input-133-9482c24a22a4>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-133-9482c24a22a4>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-133-9482c24a22a4>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Worthiness Score: 5\n",
      "count    153755.000000\n",
      "mean          4.788443\n",
      "std           1.046105\n",
      "min           4.000000\n",
      "25%           4.000000\n",
      "50%           5.000000\n",
      "75%           5.000000\n",
      "max          16.000000\n",
      "Name: Credit Worthiness Score, dtype: float64\n",
      "Credit Worthiness Score\n",
      "4     75715\n",
      "5     51546\n",
      "6     16445\n",
      "7      6060\n",
      "8      2455\n",
      "9       946\n",
      "10      321\n",
      "11      130\n",
      "12       63\n",
      "13       39\n",
      "14       18\n",
      "15       14\n",
      "16        3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-133-9482c24a22a4>:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10['Credit Worthiness Score'] = scores\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Example data loading (adjust the path and file name as needed)\n",
    "df_extract_21 = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "\n",
    "# Extract relevant features\n",
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                               'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                               'CNT_FAM_MEMBERS']]\n",
    "\n",
    "# Ensure the target column is present\n",
    "if 'TARGET' not in df_extract_21.columns:\n",
    "    raise KeyError(\"The target column 'TARGET' is not found in the dataset.\")\n",
    "\n",
    "# Handle missing values\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "categorical_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "\n",
    "df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
    "for column in categorical_columns:\n",
    "    df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = df_extract_10\n",
    "target = df_extract_21['TARGET']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_classifier = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Function to calculate credit worthiness score\n",
    "def get_credit_worthiness_score(prob):\n",
    "    return int(prob * 16 + 4)\n",
    "\n",
    "# Make predictions on new data and get the probabilities\n",
    "new_data = pd.DataFrame({\n",
    "    'AMT_INCOME_TOTAL': [200000],\n",
    "    'AMT_CREDIT': [500000],\n",
    "    'AMT_ANNUITY': [25000],\n",
    "    'AMT_GOODS_PRICE': [450000],\n",
    "    'NAME_INCOME_TYPE': ['Working'],\n",
    "    'NAME_EDUCATION_TYPE': ['Higher education'],\n",
    "    'DAYS_BIRTH': [-10000],\n",
    "    'DAYS_EMPLOYED': [-2000],\n",
    "    'ORGANIZATION_TYPE': ['Business Entity Type 3'],\n",
    "    'CNT_FAM_MEMBERS': [2]\n",
    "})\n",
    "\n",
    "# Ensure new data columns match the training data\n",
    "new_data = new_data[features.columns]\n",
    "\n",
    "# Encode new data using the same label encoders\n",
    "for column in categorical_columns:\n",
    "    new_data[column] = label_encoders[column].transform(new_data[column])\n",
    "\n",
    "# Get the probability of the positive class\n",
    "prob = xgb_classifier.predict_proba(new_data)[:, 1][0]\n",
    "\n",
    "# Generate the credit worthiness score\n",
    "score = get_credit_worthiness_score(prob)\n",
    "print(f'Credit Worthiness Score: {score}')\n",
    "\n",
    "# Predict probabilities for the entire dataset\n",
    "probabilities = xgb_classifier.predict_proba(features)[:, 1]\n",
    "\n",
    "# Generate credit worthiness scores\n",
    "scores = [get_credit_worthiness_score(prob) for prob in probabilities]\n",
    "\n",
    "# Add the scores to the DataFrame\n",
    "df_extract_10['Credit Worthiness Score'] = scores\n",
    "\n",
    "# Summarize the scores\n",
    "summary = df_extract_10['Credit Worthiness Score'].describe()\n",
    "print(summary)\n",
    "\n",
    "# Optionally, print the distribution of scores\n",
    "score_distribution = df_extract_10['Credit Worthiness Score'].value_counts().sort_index()\n",
    "print(score_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-134-3e8b13797b43>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
      "<ipython-input-134-3e8b13797b43>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
      "<ipython-input-134-3e8b13797b43>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-134-3e8b13797b43>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
      "<ipython-input-134-3e8b13797b43>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_extract_10[column] = le.fit_transform(df_extract_10[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Precision Score: 0.5\n",
      "\n",
      "XGBoost Evaluation:\n",
      "Accuracy: 0.9201001593444116\n",
      "AUC-ROC: 0.5007433144494006\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     28294\n",
      "           1       0.50      0.00      0.00      2457\n",
      "\n",
      "    accuracy                           0.92     30751\n",
      "   macro avg       0.71      0.50      0.48     30751\n",
      "weighted avg       0.89      0.92      0.88     30751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, precision_score\n",
    "\n",
    "\n",
    "df_extract_21 = pd.read_csv('/Users/manikanr/Downloads/assignment/train_data.csv')\n",
    "\n",
    "# Extract relevant features\n",
    "df_extract_10 = df_extract_21[['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                               'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                               'CNT_FAM_MEMBERS']]\n",
    "\n",
    "# Ensure the target column is present\n",
    "if 'TARGET' not in df_extract_21.columns:\n",
    "    raise KeyError(\"The target column 'TARGET' is not found in the dataset.\")\n",
    "\n",
    "# Handle missing values\n",
    "numerical_columns = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "categorical_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'ORGANIZATION_TYPE']\n",
    "\n",
    "df_extract_10[numerical_columns] = df_extract_10[numerical_columns].fillna(df_extract_10[numerical_columns].mean())\n",
    "for column in categorical_columns:\n",
    "    df_extract_10[column] = df_extract_10[column].fillna(df_extract_10[column].mode()[0])\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_extract_10[column] = le.fit_transform(df_extract_10[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "features = df_extract_10\n",
    "target = df_extract_21['TARGET']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_classifier = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_classifier.predict(x_test)\n",
    "\n",
    "# Calculate precision score\n",
    "xgb_precision = precision_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost Precision Score: {xgb_precision}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "xgb_auc_roc = roc_auc_score(y_test, y_pred_xgb)\n",
    "xgb_report = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"\\nXGBoost Evaluation:\")\n",
    "print(f\"Accuracy: {xgb_accuracy}\")\n",
    "print(f\"AUC-ROC: {xgb_auc_roc}\")\n",
    "print(\"Classification Report:\\n\", xgb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Accuracy: 92% XGBoost Accuracy: 92% Both had an f1-score of .96, indicating both are good models as we are applying them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct the data imbalance\n",
    "\n",
    "The test target values with 1 is just ~12k entries while with 0 is ~140,000. Correct this data imbalance with over sampling the minority class with SMOTE method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of y_resampled with values of 0: 141343\n"
     ]
    }
   ],
   "source": [
    "# SMOTE method\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 2: Load your dataset\n",
    "X = df_extract_10.drop('TARGET', axis=1).values\n",
    "y = df_extract_10['TARGET'].values\n",
    "\n",
    "# Step 3: Apply SMOTE to generate synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "count_minority_class = np.sum(y_resampled == 0)\n",
    "print(f'Count of y_resampled with values of 0: {count_minority_class}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit with Convolutional Neural Networks\n",
    "\n",
    " Convolutional Nural Networks are good for classification tasks. Follow the below steps to do model fit. Develop an aggregate score with a scale (1-20) and set a threshold for a YES/NO decision point.\n",
    "\n",
    " 1. Do the scaling and split the train-test using scikit-learn.\n",
    " 2. Build the model using CNN.\n",
    " 3. Train the model.\n",
    " 4. Model Evaluation.\n",
    " 5. Getting Decision Threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and Split the train-test data\n",
    "\n",
    "Do the scaling and split the train-test using scikit-learn with python code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Reshape features for CNN\n",
    "features_scaled_reshaped = features_scaled.reshape(features_scaled.shape[0], features_scaled.shape[1], 1)\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_scaled_reshaped, y_resampled, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model using CNN\n",
    "\n",
    "Build the model and do the fit with Tensorflow-keras libraries for CNN. Use Relu as activation layer, use Adam optimizer and use mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPooling1D\n",
    "\n",
    "# Reshape the data to be compatible with Conv1D\n",
    "#X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "#X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(features_scaled_reshaped.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Now Train the model with fit method using python code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4742 - accuracy: 0.7584 - val_loss: 0.4619 - val_accuracy: 0.7648\n",
      "Epoch 2/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4712 - accuracy: 0.7601 - val_loss: 0.4591 - val_accuracy: 0.7671\n",
      "Epoch 3/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4697 - accuracy: 0.7608 - val_loss: 0.4621 - val_accuracy: 0.7632\n",
      "Epoch 4/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4678 - accuracy: 0.7626 - val_loss: 0.4666 - val_accuracy: 0.7578\n",
      "Epoch 5/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4663 - accuracy: 0.7625 - val_loss: 0.4619 - val_accuracy: 0.7630\n",
      "Epoch 6/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4644 - accuracy: 0.7646 - val_loss: 0.4519 - val_accuracy: 0.7710\n",
      "Epoch 7/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4637 - accuracy: 0.7643 - val_loss: 0.4531 - val_accuracy: 0.7695\n",
      "Epoch 8/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4621 - accuracy: 0.7652 - val_loss: 0.4608 - val_accuracy: 0.7632\n",
      "Epoch 9/50\n",
      "5654/5654 [==============================] - 8s 2ms/step - loss: 0.4593 - accuracy: 0.7660 - val_loss: 0.4532 - val_accuracy: 0.7671\n",
      "Epoch 10/50\n",
      "5654/5654 [==============================] - 7s 1ms/step - loss: 0.4587 - accuracy: 0.7670 - val_loss: 0.4576 - val_accuracy: 0.7637\n",
      "Epoch 11/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4570 - accuracy: 0.7674 - val_loss: 0.4431 - val_accuracy: 0.7748\n",
      "Epoch 12/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4568 - accuracy: 0.7674 - val_loss: 0.4437 - val_accuracy: 0.7735\n",
      "Epoch 13/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4545 - accuracy: 0.7684 - val_loss: 0.4423 - val_accuracy: 0.7746\n",
      "Epoch 14/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4536 - accuracy: 0.7690 - val_loss: 0.4429 - val_accuracy: 0.7755\n",
      "Epoch 15/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4534 - accuracy: 0.7697 - val_loss: 0.4426 - val_accuracy: 0.7733\n",
      "Epoch 16/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4517 - accuracy: 0.7704 - val_loss: 0.4431 - val_accuracy: 0.7744\n",
      "Epoch 17/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4512 - accuracy: 0.7706 - val_loss: 0.4510 - val_accuracy: 0.7668\n",
      "Epoch 18/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4491 - accuracy: 0.7720 - val_loss: 0.4378 - val_accuracy: 0.7776\n",
      "Epoch 19/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4484 - accuracy: 0.7727 - val_loss: 0.4375 - val_accuracy: 0.7781\n",
      "Epoch 20/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4482 - accuracy: 0.7727 - val_loss: 0.4420 - val_accuracy: 0.7711\n",
      "Epoch 21/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4483 - accuracy: 0.7733 - val_loss: 0.4410 - val_accuracy: 0.7764\n",
      "Epoch 22/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4472 - accuracy: 0.7732 - val_loss: 0.4378 - val_accuracy: 0.7788\n",
      "Epoch 23/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4459 - accuracy: 0.7746 - val_loss: 0.4369 - val_accuracy: 0.7794\n",
      "Epoch 24/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4459 - accuracy: 0.7744 - val_loss: 0.4367 - val_accuracy: 0.7790\n",
      "Epoch 25/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4445 - accuracy: 0.7752 - val_loss: 0.4294 - val_accuracy: 0.7842\n",
      "Epoch 26/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4438 - accuracy: 0.7754 - val_loss: 0.4348 - val_accuracy: 0.7783\n",
      "Epoch 27/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4440 - accuracy: 0.7766 - val_loss: 0.4332 - val_accuracy: 0.7805\n",
      "Epoch 28/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4418 - accuracy: 0.7768 - val_loss: 0.4426 - val_accuracy: 0.7756\n",
      "Epoch 29/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4406 - accuracy: 0.7771 - val_loss: 0.4288 - val_accuracy: 0.7834\n",
      "Epoch 30/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4406 - accuracy: 0.7775 - val_loss: 0.4308 - val_accuracy: 0.7833\n",
      "Epoch 31/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4406 - accuracy: 0.7774 - val_loss: 0.4374 - val_accuracy: 0.7781\n",
      "Epoch 32/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4398 - accuracy: 0.7777 - val_loss: 0.4340 - val_accuracy: 0.7787\n",
      "Epoch 33/50\n",
      "5654/5654 [==============================] - 8s 1ms/step - loss: 0.4392 - accuracy: 0.7782 - val_loss: 0.4354 - val_accuracy: 0.7778\n",
      "Epoch 34/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4390 - accuracy: 0.7785 - val_loss: 0.4285 - val_accuracy: 0.7805\n",
      "Epoch 35/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4393 - accuracy: 0.7783 - val_loss: 0.4264 - val_accuracy: 0.7865\n",
      "Epoch 36/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4383 - accuracy: 0.7794 - val_loss: 0.4269 - val_accuracy: 0.7862\n",
      "Epoch 37/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4386 - accuracy: 0.7787 - val_loss: 0.4261 - val_accuracy: 0.7869\n",
      "Epoch 38/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4368 - accuracy: 0.7807 - val_loss: 0.4226 - val_accuracy: 0.7889\n",
      "Epoch 39/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4377 - accuracy: 0.7793 - val_loss: 0.4241 - val_accuracy: 0.7877\n",
      "Epoch 40/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4364 - accuracy: 0.7802 - val_loss: 0.4274 - val_accuracy: 0.7831\n",
      "Epoch 41/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4365 - accuracy: 0.7806 - val_loss: 0.4291 - val_accuracy: 0.7843\n",
      "Epoch 42/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4369 - accuracy: 0.7805 - val_loss: 0.4220 - val_accuracy: 0.7889\n",
      "Epoch 43/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4350 - accuracy: 0.7815 - val_loss: 0.4240 - val_accuracy: 0.7884\n",
      "Epoch 44/50\n",
      "5654/5654 [==============================] - 9s 2ms/step - loss: 0.4347 - accuracy: 0.7816 - val_loss: 0.4216 - val_accuracy: 0.7878\n",
      "Epoch 45/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4356 - accuracy: 0.7808 - val_loss: 0.4270 - val_accuracy: 0.7882\n",
      "Epoch 46/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4343 - accuracy: 0.7816 - val_loss: 0.4190 - val_accuracy: 0.7907\n",
      "Epoch 47/50\n",
      "5654/5654 [==============================] - 11s 2ms/step - loss: 0.4342 - accuracy: 0.7827 - val_loss: 0.4258 - val_accuracy: 0.7866\n",
      "Epoch 48/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4336 - accuracy: 0.7829 - val_loss: 0.4283 - val_accuracy: 0.7850\n",
      "Epoch 49/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4336 - accuracy: 0.7822 - val_loss: 0.4194 - val_accuracy: 0.7897\n",
      "Epoch 50/50\n",
      "5654/5654 [==============================] - 10s 2ms/step - loss: 0.4323 - accuracy: 0.7826 - val_loss: 0.4189 - val_accuracy: 0.7924\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We get ~80% accuracy for our model for 50 epochs. We can see the model is getting better with an increase in number of epochs. With more epochs, it would take more time to train the model. Care should be taken so that model doesn't overfit as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Evaluate the model and predict the values for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1767/1767 [==============================] - 1s 676us/step\n",
      "Accuracy: 0.792387420849694\n",
      "Precision: 0.8740814210360218\n",
      "Recall: 0.6842904034165108\n",
      "F1 Score: 0.7676287761808608\n",
      "AUC Score: 0.8756238699735143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81     28205\n",
      "           1       0.87      0.68      0.77     28333\n",
      "\n",
      "    accuracy                           0.79     56538\n",
      "   macro avg       0.81      0.79      0.79     56538\n",
      "weighted avg       0.81      0.79      0.79     56538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred_proba = model.predict(x_test).flatten()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'AUC Score: {auc}')\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision threshold\n",
    "\n",
    "To set a threshold for a YES/NO decision, we'll classify the predictions based on the threshold value (e.g., 6.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81     28205\n",
      "           1       0.87      0.68      0.77     28333\n",
      "\n",
      "    accuracy                           0.79     56538\n",
      "   macro avg       0.81      0.79      0.79     56538\n",
      "weighted avg       0.81      0.79      0.79     56538\n",
      "\n",
      "8834/8834 [==============================] - 6s 668us/step\n",
      "count    282686.000000\n",
      "mean          9.353785\n",
      "std           6.726406\n",
      "min           0.000000\n",
      "25%           4.000000\n",
      "50%           7.000000\n",
      "75%          16.000000\n",
      "max          20.000000\n",
      "Name: Credit Worthiness Score, dtype: float64\n",
      "Credit Worthiness Score\n",
      "0     11328\n",
      "1     19343\n",
      "2     17691\n",
      "3     16655\n",
      "4     17190\n",
      "5     18246\n",
      "6     20503\n",
      "7     27053\n",
      "8     14678\n",
      "9      9360\n",
      "10     7197\n",
      "11     6682\n",
      "12     6206\n",
      "13     5941\n",
      "14     5857\n",
      "15     5325\n",
      "16     4239\n",
      "17     2931\n",
      "18     2153\n",
      "19    32164\n",
      "20    31944\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Predict probabilities for the entire dataset\n",
    "probabilities = model.predict(features_scaled_reshaped).flatten()\n",
    "\n",
    "# Generate credit worthiness scores\n",
    "scores = [get_credit_worthiness_score(prob) for prob in probabilities]\n",
    "\n",
    "X_resampled_df = pd.DataFrame(X_resampled, columns=['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_INCOME_TYPE',\n",
    "                   'NAME_EDUCATION_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'ORGANIZATION_TYPE',\n",
    "                   'CNT_FAM_MEMBERS'])\n",
    "# Add the scores to the DataFrame\n",
    "X_resampled_df['Credit Worthiness Score'] = scores\n",
    "\n",
    "# Summarize the scores\n",
    "summary = X_resampled_df['Credit Worthiness Score'].describe()\n",
    "print(summary)\n",
    "\n",
    "# The distribution of scores\n",
    "score_distribution = X_resampled_df['Credit Worthiness Score'].value_counts().sort_index()\n",
    "print(score_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From above, we can see the credit worthiness scores are classified for different entries with mean value of 9. The accuracy is ~80% in this model with epoch size of 50 and it is still increasing. We might get better values of more than 90% with additional time for model fit and epochs close to 250.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
